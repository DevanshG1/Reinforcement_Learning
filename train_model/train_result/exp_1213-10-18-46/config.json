{"algorithm": "madre", "config": {"train": {"max_episodes": 50000, "before_train_episode": 200, "per_episode_length": 25, "reward_scale": 1.0, "single_step_mode": false, "gamma": 0.95, "TD": 1, "batch_norm": false, "tau": 0.01, "hard_action_interval": 0.3, "epsilon": 0.2, "joint_store": true, "buffer_select_with_batch_size": true, "batch_size": 4096, "mini_batch_size": 1024, "buffer_clear_rate": 0.4, "buffer_select_rate": 0.5, "lr_decay_interval": 3000, "decay_rate": 0.95, "lr_min": 1e-05, "greedy_grow_interval": 1000, "greedy": 0.7, "grow_rate": 1.1, "greedy_max": 0.9, "delta": 1e-06, "use_wandb": true}, "control": {"summary_record": true, "reward_predict_mode": "net", "print_info_every_n_step": 300, "update_every_n_ep": 4, "update_repeat_n_time": 1, "clear_buffer_every_n_ep": 1000, "plot_every_n_step": 3000000000, "render_threshold": 9999999999}, "evaluate": {"render": false, "eval_every_n_ep": 50, "eval_episode": 10}, "save": {"total_model_num": 20, "save_data_every_n_step": 2000000000}, "env": {"domain": "MPE", "scenario": "simple_spread", "adversary": true, "agent_num": 3, "action_dim": 5, "all_action_dim": [5, 5, 5], "state_dim": 18, "all_state_dim": [18, 18, 18], "action_type": "discrete", "n_action": 1}, "graph": {"atten_head_num": 8, "in_norm": false, "in_drop": false, "coef_drop": false, "residual": true, "Con1d_kernel_num": 8}, "critic": {"input_dim": 18, "output_dim": 1, "layer_num": 2, "lr": 0.001}, "actor": {"input_dim": 18, "output_dim": 5, "layer_num": 2, "lr": 0.001}, "reward": {"input_dim": 18, "output_dim": 3, "layer_num": 2, "lr": 0.001, "sdrr": 0.001, "dist_reward_fit": true, "global_reward_prediction": false, "reward_aggregation_type": "l_smo", "team_reward": false, "reward_uncertainty_type": "r_ac-dist", "eval_with_reward_uncertainty": false}, "feature": {"data": {"input_dim": 19}, "feature_extractor": {"input_dim": 19, "output_dim": 19, "gaussian_num": 5, "lr": 0.001}, "vae": {"lr": 0.001, "encoder": {"input_dim": 19, "output_dim": 19}, "decoder": {"input_dim": 19, "output_dim": 19}}}}}